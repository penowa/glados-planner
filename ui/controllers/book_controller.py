"""
Controller refatorado para gerenciamento de livros com integraÃ§Ã£o robusta com backend
"""
from PyQt6.QtCore import QObject, pyqtSignal, pyqtSlot, QThread, QTimer, Qt, QMutex, QWaitCondition
from PyQt6.QtGui import QPixmap, QPainter, QColor, QImage, QBrush, QLinearGradient
from datetime import datetime, timedelta
import logging
import json
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
import uuid
import hashlib
import re
import unicodedata
import tempfile
from difflib import SequenceMatcher
from enum import Enum

logger = logging.getLogger('GLaDOS.UI.BookController')


class BookProcessingStage(Enum):
    """EstÃ¡gios do processamento de livro"""
    INITIALIZATION = "initialization"
    ANALYSIS = "analysis"
    EXTRACTION = "extraction"
    STRUCTURING = "structuring"
    LLM_ENHANCEMENT = "llm_enhancement"
    INTEGRATION = "integration"
    SCHEDULING = "scheduling"
    COMPLETED = "completed"
    FAILED = "failed"


class BookProcessingPipeline(QThread):
    """Pipeline completo e robusto para processamento de livros"""
    
    # Sinais de progresso
    stage_started = pyqtSignal(str, str, str)  # (pipeline_id, stage, message)
    stage_progress = pyqtSignal(str, str, int, str)  # (pipeline_id, stage, percent, message)
    stage_completed = pyqtSignal(str, str, dict)  # (pipeline_id, stage, result)
    stage_failed = pyqtSignal(str, str, str)  # (pipeline_id, stage, error)
    
    # Sinais de conclusÃ£o
    pipeline_completed = pyqtSignal(str, dict)  # (pipeline_id, final_result)
    pipeline_failed = pyqtSignal(str, str)  # (pipeline_id, error)
    
    def __init__(self, controller, file_path: str, quality: str = "standard", 
                 schedule_reading: bool = True, use_llm: bool = False, config=None):
        super().__init__()
        self.controller = controller
        self.file_path = Path(file_path)
        self.quality = quality
        self.schedule_reading = schedule_reading
        self.use_llm = use_llm
        self.config = config or {}
        self.pipeline_id = str(uuid.uuid4())[:8]
        self._is_running = True
        self._current_stage = None
        
        # Estado do pipeline
        self.metadata = None
        self.book_id = None
        self.processing_result = None
        self.consolidated_result = {}
        self.extracted_content = None

         # ConfiguraÃ§Ãµes especÃ­ficas
        self.notes_config = self.config.get("notes_config", {})
        self.scheduling_config = self.config.get("scheduling_config", {})
        self.user_metadata = self.config.get("metadata", {})
 
    def _analyze_book(self) -> Dict:
        """Etapa 1: AnÃ¡lise do arquivo (atualizada para usar metadados do usuÃ¡rio)"""
        self.stage_progress.emit(self.pipeline_id, "analysis", 10, "Analisando arquivo...")
        
        # Usar book_processor para anÃ¡lise
        metadata, recommendations = self.controller.book_processor.analyze_book(str(self.file_path))
        self.metadata = metadata
        
        # Sobrescrever metadados com os fornecidos pelo usuÃ¡rio
        if self.user_metadata:
            for key, value in self.user_metadata.items():
                if value:  # SÃ³ sobrescrever se o valor nÃ£o for vazio
                    setattr(self.metadata, key, value)
        
        self.stage_progress.emit(self.pipeline_id, "analysis", 100, "AnÃ¡lise concluÃ­da")
        
        return {
            "title": metadata.title,
            "author": metadata.author,
            "total_pages": metadata.total_pages,
            "requires_ocr": metadata.requires_ocr,
            "estimated_time": metadata.estimated_processing_time,
            "recommendations": recommendations,
            "chapters_detected": len(metadata.chapters),
            "user_metadata_applied": bool(self.user_metadata)
        }
    
    def _structure_content(self) -> Dict:
        """Etapa 3: EstruturaÃ§Ã£o do conteÃºdo (atualizada para usar configuraÃ§Ãµes)"""
        self.stage_progress.emit(self.pipeline_id, "structuring", 10, "Estruturando conteÃºdo...")
        
        if not self.metadata or not self.extracted_content:
            raise Exception("ConteÃºdo nÃ£o disponÃ­vel para estruturaÃ§Ã£o")
        
        # Gerar ID consistente
        self.book_id = self.controller.generate_consistent_book_id(
            self.metadata.title, self.metadata.author
        )
        
        # Determinar estrutura baseado na configuraÃ§Ã£o
        structure_type = self.notes_config.get("structure", "Uma nota por capÃ­tulo (Recomendado)")
        
        if "Nota Ãºnica" in structure_type:
            # Criar estrutura de nota Ãºnica
            structure_result = self.controller.create_single_note_structure(
                book_id=self.book_id,
                metadata=self.metadata,
                content=self.extracted_content,
                config=self.notes_config
            )
        else:
            # Criar estrutura de diretÃ³rios no vault (padrÃ£o)
            structure_result = self.controller.create_book_structure(
                book_id=self.book_id,
                metadata=self.metadata,
                chapters=self.extracted_content,
                config=self.notes_config
            )
        
        # Criar Ã­ndice do livro
        index_result = self.controller.create_book_index(
            book_id=self.book_id,
            metadata=self.metadata,
            chapters=self.extracted_content
        )
        
        self.stage_progress.emit(self.pipeline_id, "structuring", 100, "EstruturaÃ§Ã£o concluÃ­da")
        
        return {
            "book_id": self.book_id,
            "structure_type": structure_type,
            "directory_created": structure_result.get("directory_created", False),
            "index_created": index_result.get("index_created", False),
            "notes_created": structure_result.get("notes_created", 0),
            "single_note": "Nota Ãºnica" in structure_type
        }
    
    def _schedule_reading(self) -> Dict:
        """Etapa 6: Agendamento automÃ¡tico de leitura (atualizada para usar configuraÃ§Ãµes)"""
        if not self.book_id:
            raise Exception("Book ID nÃ£o disponÃ­vel para agendamento")
        
        self.stage_progress.emit(self.pipeline_id, "scheduling", 10, "Preparando agendamento...")
        
        # Usar configuraÃ§Ãµes personalizadas se fornecidas
        scheduling_config = self.scheduling_config or {}
        
        # Agendar leitura usando AgendaManager com configuraÃ§Ãµes
        scheduling_result = self.controller.schedule_book_reading(
            book_id=self.book_id,
            title=self.metadata.title,
            total_pages=self.metadata.total_pages,
            config=scheduling_config
        )
        
        if not scheduling_result.get("success", False):
            logger.warning(f"Agendamento automÃ¡tico falhou: {scheduling_result.get('error')}")
            scheduling_result["warning"] = "Agendamento automÃ¡tico nÃ£o concluÃ­do"
        
        self.stage_progress.emit(self.pipeline_id, "scheduling", 100, "Agendamento configurado")
        
        return scheduling_result
        
    def run(self):
        """Executa pipeline completo"""
        try:
            # ETAPA 0: InicializaÃ§Ã£o
            self._run_stage(BookProcessingStage.INITIALIZATION, self._initialize_processing)
            
            # ETAPA 1: AnÃ¡lise do arquivo
            if not self._check_stop_condition():
                self._run_stage(BookProcessingStage.ANALYSIS, self._analyze_book)
            
            # ETAPA 2: ExtraÃ§Ã£o de conteÃºdo
            if not self._check_stop_condition():
                self._run_stage(BookProcessingStage.EXTRACTION, self._extract_content)
            
            # ETAPA 3: EstruturaÃ§Ã£o
            if not self._check_stop_condition():
                self._run_stage(BookProcessingStage.STRUCTURING, self._structure_content)
            
            # ETAPA 4: Aprimoramento com LLM (opcional)
            if not self._check_stop_condition() and self.use_llm:
                self._run_stage(BookProcessingStage.LLM_ENHANCEMENT, self._enhance_with_llm)
            
            # ETAPA 5: IntegraÃ§Ã£o com sistemas
            if not self._check_stop_condition():
                self._run_stage(BookProcessingStage.INTEGRATION, self._integrate_with_systems)
            
            # ETAPA 6: Agendamento automÃ¡tico
            if not self._check_stop_condition() and self.schedule_reading:
                self._run_stage(BookProcessingStage.SCHEDULING, self._schedule_reading)
            
            # ConclusÃ£o
            if not self._check_stop_condition():
                self._complete_pipeline()
                
        except Exception as e:
            logger.error(f"Erro no pipeline {self.pipeline_id}: {e}")
            self.pipeline_failed.emit(self.pipeline_id, str(e))
            
    def _run_stage(self, stage: BookProcessingStage, stage_func):
        """Executa um estÃ¡gio do pipeline"""
        try:
            self._current_stage = stage
            stage_name = stage.value
            self.stage_started.emit(self.pipeline_id, stage_name, f"Iniciando {stage_name}...")
            
            # Executar funÃ§Ã£o do estÃ¡gio
            result = stage_func()
            
            # Atualizar estado consolidado
            self.consolidated_result[stage_name] = result
            
            # Emitir conclusÃ£o
            self.stage_completed.emit(self.pipeline_id, stage_name, result)
            
        except Exception as e:
            logger.error(f"Erro no estÃ¡gio {stage.value} do pipeline {self.pipeline_id}: {e}")
            self.stage_failed.emit(self.pipeline_id, stage.value, str(e))
            raise
    
    def _initialize_processing(self) -> Dict:
        """Etapa 0: InicializaÃ§Ã£o do processamento"""
        self.stage_progress.emit(self.pipeline_id, "initialization", 10, "Inicializando processamento...")
        
        # Verificar se arquivo existe
        if not self.file_path.exists():
            raise FileNotFoundError(f"Arquivo nÃ£o encontrado: {self.file_path}")
        
        # Verificar formato suportado
        supported_formats = ['.pdf', '.epub']
        if self.file_path.suffix.lower() not in supported_formats:
            raise ValueError(f"Formato nÃ£o suportado: {self.file_path.suffix}. Formatos suportados: {supported_formats}")
        
        # Verificar tamanho do arquivo
        file_size_mb = self.file_path.stat().st_size / (1024 * 1024)
        if file_size_mb > 100:
            logger.warning(f"Arquivo grande: {file_size_mb:.1f}MB")
        
        self.stage_progress.emit(self.pipeline_id, "initialization", 100, "InicializaÃ§Ã£o concluÃ­da")
        
        return {
            "file_path": str(self.file_path),
            "file_size_mb": file_size_mb,
            "format": self.file_path.suffix,
            "requires_llm": self.use_llm,
            "quality": self.quality
        }
    
    def _analyze_book(self) -> Dict:
        """Etapa 1: AnÃ¡lise do arquivo"""
        self.stage_progress.emit(self.pipeline_id, "analysis", 10, "Analisando arquivo...")
        
        # Usar book_processor para anÃ¡lise
        metadata, recommendations = self.controller.book_processor.analyze_book(str(self.file_path))
        self.metadata = metadata

        # Aplicar metadados informados no diÃ¡logo de importaÃ§Ã£o.
        if self.user_metadata:
            for key, value in self.user_metadata.items():
                if value not in (None, "", []):
                    setattr(self.metadata, key, value)
        
        self.stage_progress.emit(self.pipeline_id, "analysis", 100, "AnÃ¡lise concluÃ­da")
        
        return {
            "title": self.metadata.title,
            "author": self.metadata.author,
            "total_pages": self.metadata.total_pages,
            "requires_ocr": self.metadata.requires_ocr,
            "estimated_time": self.metadata.estimated_processing_time,
            "recommendations": recommendations,
            "chapters_detected": len(self.metadata.chapters),
            "user_metadata_applied": bool(self.user_metadata)
        }
    
    def _extract_content(self) -> Dict:
        """Etapa 2: ExtraÃ§Ã£o de conteÃºdo"""
        self.stage_progress.emit(self.pipeline_id, "extraction", 10, "Extraindo conteÃºdo...")
        
        # Determinar qualidade
        from core.modules.book_processor import ProcessingQuality
        quality_map = {
            'draft': ProcessingQuality.DRAFT,
            'standard': ProcessingQuality.STANDARD,
            'high': ProcessingQuality.HIGH,
            'academic': ProcessingQuality.ACADEMIC
        }
        processing_quality = quality_map.get(self.quality, ProcessingQuality.STANDARD)

        # ExtraÃ§Ã£o tÃ©cnica em diretÃ³rio temporÃ¡rio para evitar criaÃ§Ã£o de estrutura
        # paralela no vault com metadados crus do PDF.
        temp_output_dir = (
            Path(tempfile.gettempdir()) /
            "glados_book_processing" /
            self.pipeline_id
        )
        temp_output_dir.mkdir(parents=True, exist_ok=True)
        
        # Processar livro usando book_processor
        result = self.controller.book_processor.process_book(
            filepath=str(self.file_path),
            quality=processing_quality,
            output_dir=str(temp_output_dir),
            schedule_night=False,  # Processar imediatamente
            force_immediate=True,
            integrate_with_vault=False
        )
        
        if result.status.value == "failed":
            raise Exception(result.error or "Erro no processamento")
        if result.status.value == "scheduled":
            raise Exception("Processamento foi agendado, mas esta operaÃ§Ã£o requer execuÃ§Ã£o imediata")
        
        self.processing_result = result
        self.extracted_content = result.processed_chapters
        
        # Se necessÃ¡rio, usar LLM para extraÃ§Ã£o aprimorada
        if result.metadata.requires_ocr and self.use_llm:
            logger.info("Usando LLM para extraÃ§Ã£o aprimorada de texto")
            
        self.stage_progress.emit(self.pipeline_id, "extraction", 100, "ExtraÃ§Ã£o concluÃ­da")
        
        return {
            "chapters_extracted": len(result.processed_chapters),
            "total_pages": result.metadata.total_pages,
            "requires_ocr": result.metadata.requires_ocr,
            "extraction_method": "standard" + ("+llm" if self.use_llm else ""),
            "warnings": result.warnings or []
        }
    
    def _structure_content(self) -> Dict:
        """Etapa 3: EstruturaÃ§Ã£o do conteÃºdo"""
        self.stage_progress.emit(self.pipeline_id, "structuring", 10, "Estruturando conteÃºdo...")
        
        if not self.metadata or not self.extracted_content:
            raise Exception("ConteÃºdo nÃ£o disponÃ­vel para estruturaÃ§Ã£o")
        
        # Gerar ID consistente
        self.book_id = self.controller.generate_consistent_book_id(
            self.metadata.title, self.metadata.author
        )
        
        # Sempre criar notas por capÃ­tulo
        chapters_result = self.controller.create_book_structure(
            book_id=self.book_id,
            metadata=self.metadata,
            chapters=self.extracted_content
        )

        # Sempre criar nota Ãºnica com conteÃºdo completo
        full_note_result = self.controller.create_single_note_structure(
            book_id=self.book_id,
            metadata=self.metadata,
            content=self.extracted_content,
            config=self.notes_config
        )
        
        # Criar Ã­ndice do livro
        index_result = self.controller.create_book_index(
            book_id=self.book_id,
            metadata=self.metadata,
            chapters=self.extracted_content
        )
        
        self.stage_progress.emit(self.pipeline_id, "structuring", 100, "EstruturaÃ§Ã£o concluÃ­da")
        
        return {
            "book_id": self.book_id,
            "directory_created": chapters_result.get("directory_created", False),
            "index_created": index_result.get("index_created", False),
            "chapter_notes_created": chapters_result.get("notes_created", 0),
            "full_note_created": full_note_result.get("notes_created", 0) > 0,
            "notes_created": chapters_result.get("notes_created", 0) + full_note_result.get("notes_created", 0),
            "warnings": (self.processing_result.warnings if self.processing_result else []) or []
        }
    
    def _enhance_with_llm(self) -> Dict:
        """Etapa 4: Aprimoramento com LLM"""
        if not self.use_llm:
            return {"llm_used": False, "message": "LLM nÃ£o habilitado"}
        
        self.stage_progress.emit(self.pipeline_id, "llm_enhancement", 10, "Aprimorando com LLM...")
        
        try:
            # Importar processador LLM
            from core.modules.llm_pdf_transcriber import LLMPDFProcessor
            
            # Inicializar processador LLM
            llm_processor = LLMPDFProcessor()
            
            # Processar pÃ¡ginas que precisam de melhoria
            improved_pages = 0
            if hasattr(self.metadata, 'requires_ocr') and self.metadata.requires_ocr:
                # Processar algumas pÃ¡ginas com LLM
                pages_to_process = min(10, self.metadata.total_pages)
                
                for page_num in range(pages_to_process):
                    if self._check_stop_condition():
                        break
                    
                    self.stage_progress.emit(
                        self.pipeline_id, 
                        "llm_enhancement",
                        int(10 + (page_num / pages_to_process) * 90),
                        f"Aprimorando pÃ¡gina {page_num + 1}/{pages_to_process} com LLM..."
                    )
                    
                    # Aqui vocÃª implementaria o processamento real com LLM
                    # Por enquanto, apenas simulamos
                    improved_pages += 1
            
            self.stage_progress.emit(self.pipeline_id, "llm_enhancement", 100, "Aprimoramento com LLM concluÃ­do")
            
            return {
                "llm_used": True,
                "pages_improved": improved_pages,
                "enhancement_method": "llm_ocr_enhancement"
            }
            
        except ImportError:
            logger.warning("MÃ³dulo LLM nÃ£o disponÃ­vel")
            return {"llm_used": False, "error": "MÃ³dulo LLM nÃ£o disponÃ­vel"}
        except Exception as e:
            logger.error(f"Erro no aprimoramento com LLM: {e}")
            return {"llm_used": False, "error": str(e)}
    
    def _integrate_with_systems(self) -> Dict:
        """Etapa 5: IntegraÃ§Ã£o com sistemas"""
        self.stage_progress.emit(self.pipeline_id, "integration", 10, "Integrando com sistemas...")
        
        if not self.book_id or not self.metadata:
            raise Exception("Dados do livro nÃ£o disponÃ­veis para integraÃ§Ã£o")
        
        # Registrar no sistema de leitura
        integration_result = self.controller.register_book_in_system(
            book_id=self.book_id,
            title=self.metadata.title,
            author=self.metadata.author,
            total_pages=self.metadata.total_pages,
            file_path=self.file_path
        )
        
        # Registrar no vault
        if self.controller.vault_manager:
            vault_result = self.controller.integrate_with_vault(
                book_id=self.book_id,
                metadata=self.metadata,
                chapters=self.extracted_content
            )
            integration_result.update(vault_result)
        
        # Registrar no cache interno
        self.controller.book_registry[self.book_id] = {
            "title": self.metadata.title,
            "author": self.metadata.author,
            "total_pages": self.metadata.total_pages,
            "file_path": str(self.file_path),
            "processed_at": datetime.now().isoformat(),
            "quality": self.quality,
            "chapters": len(self.extracted_content) if self.extracted_content else 0
        }
        
        self.stage_progress.emit(self.pipeline_id, "integration", 100, "IntegraÃ§Ã£o concluÃ­da")
        
        return integration_result
    
    def _schedule_reading(self) -> Dict:
        """Etapa 6: Agendamento automÃ¡tico de leitura"""
        if not self.book_id:
            raise Exception("Book ID nÃ£o disponÃ­vel para agendamento")
        
        self.stage_progress.emit(self.pipeline_id, "scheduling", 10, "Preparando agendamento...")
        
        # Agendar leitura usando AgendaManager
        scheduling_result = self.controller.schedule_book_reading(
            book_id=self.book_id,
            title=self.metadata.title,
            total_pages=self.metadata.total_pages
        )
        
        if not scheduling_result.get("success", False):
            logger.warning(f"Agendamento automÃ¡tico falhou: {scheduling_result.get('error')}")
            scheduling_result["warning"] = "Agendamento automÃ¡tico nÃ£o concluÃ­do"
        
        self.stage_progress.emit(self.pipeline_id, "scheduling", 100, "Agendamento configurado")
        
        return scheduling_result
    
    def _complete_pipeline(self):
        """Finaliza o pipeline com sucesso"""
        warnings = []
        extraction_stage = self.consolidated_result.get("extraction", {})
        if isinstance(extraction_stage, dict):
            warnings.extend(extraction_stage.get("warnings", []) or [])
        structure_stage = self.consolidated_result.get("structuring", {})
        if isinstance(structure_stage, dict):
            warnings.extend(structure_stage.get("warnings", []) or [])

        final_result = {
            "status": "completed",
            "pipeline_id": self.pipeline_id,
            "book_id": self.book_id,
            "title": self.metadata.title if self.metadata else "Desconhecido",
            "author": self.metadata.author if self.metadata else "Desconhecido",
            "total_pages": self.metadata.total_pages if self.metadata else 0,
            "chapters": len(self.extracted_content) if self.extracted_content else 0,
            "quality": self.quality,
            "use_llm": self.use_llm,
            "stages": self.consolidated_result,
            "warnings": warnings,
            "timestamp": datetime.now().isoformat(),
            "processing_time": (
                datetime.now() - datetime.fromisoformat(
                    self.consolidated_result.get("initialization", {}).get("timestamp", datetime.now().isoformat())
                )
            ).total_seconds()
        }
        
        # Salvar no histÃ³rico
        self.controller.save_to_history(final_result)
        
        # Emitir sinal de conclusÃ£o
        self.pipeline_completed.emit(self.pipeline_id, final_result)
        
        logger.info(f"Pipeline {self.pipeline_id} concluÃ­do: {final_result.get('title', 'Desconhecido')}")
    
    def _check_stop_condition(self) -> bool:
        """Verifica se o pipeline deve ser interrompido"""
        return not self._is_running
    
    def stop(self):
        """Para o pipeline de forma segura"""
        self._is_running = False
        self.quit()
        self.wait(2000)


class BookController(QObject):
    """Controller robusto para gerenciamento completo de livros"""
    
    # Sinais principais
    book_processing_started = pyqtSignal(str, str, dict)  # (pipeline_id, file_name, settings)
    book_processing_completed = pyqtSignal(str, dict)  # (pipeline_id, result)
    book_processing_failed = pyqtSignal(str, str)  # (pipeline_id, error)
    book_processing_progress = pyqtSignal(str, str, int, str)  # (pipeline_id, stage, percent, message)
    
    book_scheduled = pyqtSignal(str, dict)  # (book_id, scheduling_result)
    book_registered = pyqtSignal(str, dict)  # (book_id, registration_result)
    book_structure_created = pyqtSignal(str, dict)  # (book_id, structure_result)
    
    def __init__(self, pdf_processor, book_processor, reading_manager=None, 
                 agenda_controller=None, vault_manager=None):
        super().__init__()
        self.pdf_processor = pdf_processor
        self.book_processor = book_processor
        self.reading_manager = reading_manager
        self.agenda_controller = agenda_controller
        self.vault_manager = vault_manager
        
        # Gerenciamento de pipelines ativos
        self.active_pipelines: Dict[str, BookProcessingPipeline] = {}
        self.pipeline_mutex = QMutex()
        
        # Cache e estado
        self.books_cache = {}
        self.book_registry = {}
        self.processing_history = []
        
        # ConfiguraÃ§Ã£o
        self.auto_schedule_reading = True
        self.default_pages_per_day = 10
        self.default_scheduling_strategy = "balanced"
        self.default_quality = "standard"
        self.default_use_llm = False
        
        # Inicializar componentes
        self._initialize_components()
        
        # Timer de manutenÃ§Ã£o
        self.maintenance_timer = QTimer()
        self.maintenance_timer.timeout.connect(self._perform_maintenance)
        self.maintenance_timer.start(300000)  # 5 minutos
        
        logger.info("BookController inicializado com gerenciamento robusto")
    
    def _initialize_components(self):
        """Inicializa componentes do sistema"""
        try:
            # Verificar se os mÃ³dulos estÃ£o disponÃ­veis
            self.has_llm = self._check_llm_availability()
            self.has_agenda = self.agenda_controller is not None
            self.has_vault = self.vault_manager is not None
            
            logger.info(f"Componentes disponÃ­veis - LLM: {self.has_llm}, Agenda: {self.has_agenda}, Vault: {self.has_vault}")
            
        except Exception as e:
            logger.error(f"Erro na inicializaÃ§Ã£o de componentes: {e}")
    
    def _check_llm_availability(self) -> bool:
        """Verifica se o mÃ³dulo LLM estÃ¡ disponÃ­vel"""
        try:
            from core.modules.llm_pdf_transcriber import LLMPDFProcessor
            return True
        except ImportError:
            return False
    
    # ====== MÃ‰TODOS PÃšBLICOS PRINCIPAIS ======
    
    @pyqtSlot(str, str, bool, bool)
    def process_book(self, file_path: str, quality: str = None, 
                    auto_schedule: bool = None, use_llm: bool = None) -> str:
        """
        Inicia processamento completo de um livro
        
        Args:
            file_path: Caminho para o arquivo do livro
            quality: Qualidade do processamento (draft, standard, high, academic)
            auto_schedule: Se True, agenda automaticamente apÃ³s processamento
            use_llm: Se True, usa LLM para aprimoramento
            
        Returns:
            pipeline_id: ID para acompanhamento do processamento
        """
        self.pipeline_mutex.lock()
        try:
            # Usar valores padrÃ£o se nÃ£o especificados
            quality = quality or self.default_quality
            auto_schedule = auto_schedule if auto_schedule is not None else self.auto_schedule_reading
            use_llm = use_llm if use_llm is not None else self.default_use_llm
            
            # Validar parÃ¢metros
            if quality not in ['draft', 'standard', 'high', 'academic']:
                logger.warning(f"Qualidade invÃ¡lida: {quality}. Usando padrÃ£o: {self.default_quality}")
                quality = self.default_quality
            
            # Validar arquivo
            if not Path(file_path).exists():
                raise FileNotFoundError(f"Arquivo nÃ£o encontrado: {file_path}")
            
            # Criar pipeline
            pipeline = BookProcessingPipeline(
                controller=self,
                file_path=file_path,
                quality=quality,
                schedule_reading=auto_schedule,
                use_llm=use_llm and self.has_llm  # SÃ³ usar LLM se disponÃ­vel
            )
            
            pipeline_id = pipeline.pipeline_id
            
            # Conectar sinais do pipeline
            pipeline.stage_started.connect(self._on_stage_started)
            pipeline.stage_progress.connect(self._on_stage_progress)
            pipeline.stage_completed.connect(self._on_stage_completed)
            pipeline.stage_failed.connect(self._on_stage_failed)
            pipeline.pipeline_completed.connect(self._on_pipeline_completed)
            pipeline.pipeline_failed.connect(self._on_pipeline_failed)
            
            # Registrar pipeline ativo
            self.active_pipelines[pipeline_id] = pipeline
            
            # Iniciar pipeline
            pipeline.start()
            
            # Emitir sinal de inÃ­cio
            file_name = Path(file_path).stem
            settings = {
                "quality": quality,
                "auto_schedule": auto_schedule,
                "use_llm": use_llm,
                "timestamp": datetime.now().isoformat()
            }
            self.book_processing_started.emit(pipeline_id, file_name, settings)
            
            logger.info(f"Pipeline {pipeline_id} iniciado para: {file_name} (qualidade: {quality}, LLM: {use_llm})")
            
            return pipeline_id
            
        except Exception as e:
            logger.error(f"Erro ao iniciar processamento: {e}")
            raise
        finally:
            self.pipeline_mutex.unlock()
    
    @pyqtSlot(str, result=dict)
    def get_book_status(self, book_id: str) -> Dict:
        """
        ObtÃ©m status completo de um livro
        
        Args:
            book_id: ID do livro
            
        Returns:
            Status do livro
        """
        status = {
            "book_id": book_id,
            "found": False,
            "systems": {}
        }
        
        # Verificar no registro interno
        if book_id in self.book_registry:
            status["found"] = True
            status["registry"] = self.book_registry[book_id]
        
        # Verificar no ReadingManager
        if self.reading_manager:
            try:
                progress = self.reading_manager.get_reading_progress(book_id)
                if progress:
                    status["systems"]["reading_manager"] = {
                        "registered": True,
                        "progress": progress
                    }
                else:
                    status["systems"]["reading_manager"] = {"registered": False}
            except Exception as e:
                status["systems"]["reading_manager"] = {"registered": False, "error": str(e)}
        
        # Verificar no vault
        if self.vault_manager and book_id in self.book_registry:
            try:
                book_info = self.book_registry[book_id]
                author = book_info.get("author", "")
                title = book_info.get("title", "")
                
                # Verificar se diretÃ³rio existe
                vault_path = self.vault_manager.vault_path
                book_dir = vault_path / "01-LEITURAS" / author / title
                
                status["systems"]["vault"] = {
                    "directory_exists": book_dir.exists(),
                    "notes_count": len(list(book_dir.glob("*.md"))) if book_dir.exists() else 0
                }
            except Exception as e:
                status["systems"]["vault"] = {"error": str(e)}
        
        # Verificar na agenda
        if self.agenda_controller:
            try:
                # Verificar se hÃ¡ eventos agendados para este livro
                # (implementaÃ§Ã£o depende da API do AgendaController)
                status["systems"]["agenda"] = {"registered": "unknown"}
            except Exception as e:
                status["systems"]["agenda"] = {"error": str(e)}
        
        return status
    
    @pyqtSlot(str, int, int)
    def process_additional_chapters(self, book_id: str, start_chapter: int, num_chapters: int):
        """
        Processa capÃ­tulos adicionais de um livro jÃ¡ registrado
        
        Args:
            book_id: ID do livro
            start_chapter: CapÃ­tulo inicial
            num_chapters: NÃºmero de capÃ­tulos a processar
        """
        try:
            if book_id not in self.book_registry:
                raise ValueError(f"Livro {book_id} nÃ£o encontrado no registro")
            
            book_info = self.book_registry[book_id]
            file_path = book_info.get("file_path")
            
            if not file_path or not Path(file_path).exists():
                raise FileNotFoundError(f"Arquivo original nÃ£o encontrado: {file_path}")
            
            # Usar ChapterProcessor para processar capÃ­tulos adicionais
            from core.modules.book_processor import ChapterProcessor
            
            chapter_processor = ChapterProcessor(self.vault_manager)
            
            result = chapter_processor.process_chapters(
                pdf_path=file_path,
                num_chapters=num_chapters,
                start_chapter=start_chapter,
                book_id=book_id
            )
            
            if result.get("success"):
                # Atualizar registro
                self.book_registry[book_id]["chapters"] = result.get("next_chapter", 1) - 1
                
                # Emitir sinal
                self.book_processing_completed.emit(
                    f"chapters_{book_id}_{datetime.now().timestamp()}",
                    result
                )
                
                logger.info(f"CapÃ­tulos adicionais processados para {book_id}: {result.get('chapters_processed')} capÃ­tulos")
            else:
                raise Exception(result.get("error", "Erro desconhecido"))
                
        except Exception as e:
            logger.error(f"Erro processando capÃ­tulos adicionais: {e}")
            self.book_processing_failed.emit(book_id, str(e))
    
    # ====== MÃ‰TODOS DE INTEGRAÃ‡ÃƒO ======
    
    def generate_consistent_book_id(self, title: str, author: str) -> str:
        """Gera ID consistente para todos os sistemas"""
        # Normalizar strings
        norm_title = re.sub(r'\s+', ' ', title.strip().lower())
        norm_author = re.sub(r'\s+', ' ', author.strip().lower())
        
        # Gerar hash consistente
        content = f"{norm_title}||{norm_author}||{datetime.now().strftime('%Y%m')}"
        return hashlib.sha256(content.encode()).hexdigest()[:16]
    
    def create_book_structure(self, book_id: str, metadata, chapters: List[Dict]) -> Dict:
        """Cria estrutura de diretÃ³rios e notas para o livro"""
        result = {
            "book_id": book_id,
            "directory_created": False,
            "notes_created": 0,
            "errors": []
        }
        
        try:
            if not self.vault_manager:
                result["errors"].append("VaultManager nÃ£o disponÃ­vel")
                return result
            
            # Sanitizar nomes
            safe_author = self._resolve_author_directory_name(metadata.author or "Autor Desconhecido")
            safe_title = self._sanitize_filename(metadata.title)
            
            # Criar diretÃ³rio principal
            book_dir = self.vault_manager.vault_path / "01-LEITURAS" / safe_author / safe_title
            book_dir.mkdir(parents=True, exist_ok=True)
            result["directory_created"] = True
            result["directory_path"] = str(book_dir)
            
            # Criar notas para cada capÃ­tulo
            for chapter in chapters:
                try:
                    chapter_num = chapter.get('chapter_num') or chapter.get('number') or 0
                    chapter_title = chapter.get('chapter_title') or chapter.get('title') or f"CapÃ­tulo {chapter_num}"
                    content = chapter.get('content', '')
                    
                    # Nome do arquivo
                    filename = f"{chapter_num:03d} - {self._sanitize_filename(chapter_title)}.md"
                    relative_path = f"01-LEITURAS/{safe_author}/{safe_title}/{filename}"
                    
                    # Frontmatter
                    frontmatter = {
                        'title': chapter_title,
                        'book': metadata.title,
                        'author': metadata.author,
                        'chapter': chapter_num,
                        'pages': chapter.get('pages') or f"{chapter.get('start_page', 'N/A')}-{chapter.get('end_page', 'N/A')}",
                        'book_id': book_id,
                        'tags': ['livro', 'capitulo']
                    }
                    
                    # ConteÃºdo da nota
                    note_content = f"""# {chapter_title}

## ğŸ“š Livro
[[{metadata.title}]]

## ğŸ“– InformaÃ§Ãµes
- **Livro**: {metadata.title}
- **Autor**: {metadata.author}
- **CapÃ­tulo**: {chapter_num}
- **PÃ¡ginas**: {chapter.get('pages', 'N/A')}

## ğŸ“ ConteÃºdo
{content}

## ğŸ’­ AnotaÃ§Ãµes
<!-- Adicione suas anotaÃ§Ãµes aqui -->

## ğŸ”— Links
[[{metadata.title}]] | [[Ãndice - {metadata.title}]]
"""
                    
                    # Criar nota
                    existing_note = self.vault_manager.get_note_by_path(relative_path)
                    if existing_note:
                        self.vault_manager.update_note(
                            relative_path,
                            content=note_content,
                            frontmatter=frontmatter
                        )
                    else:
                        self.vault_manager.create_note(
                            relative_path,
                            content=note_content,
                            frontmatter=frontmatter
                        )
                    
                    result["notes_created"] += 1
                    
                except Exception as e:
                    result["errors"].append(f"Erro criando capÃ­tulo {chapter_num}: {e}")
            
            # Emitir sinal
            self.book_structure_created.emit(book_id, result)
            
        except Exception as e:
            result["errors"].append(f"Erro geral na criaÃ§Ã£o da estrutura: {e}")
        
        return result
    
    def create_book_index(self, book_id: str, metadata, chapters: List[Dict]) -> Dict:
        """Cria Ã­ndice do livro no vault"""
        result = {
            "book_id": book_id,
            "index_created": False
        }
        
        try:
            if not self.vault_manager:
                return result
            
            safe_author = self._resolve_author_directory_name(metadata.author or "Autor Desconhecido")
            safe_title = self._sanitize_filename(metadata.title)
            
            # Caminho para o Ã­ndice
            index_path = f"01-LEITURAS/{safe_author}/{safe_title}/ğŸ“– {safe_title}.md"
            
            # Frontmatter
            frontmatter = {
                'title': metadata.title,
                'author': metadata.author,
                'type': 'livro',
                'book_id': book_id,
                'total_pages': metadata.total_pages,
                'total_chapters': len(chapters),
                'processed_date': datetime.now().isoformat(),
                'tags': ['livro', 'indice']
            }
            
            # Lista de capÃ­tulos
            chapters_list = ""
            for chapter in chapters:
                chapter_num = chapter.get('chapter_num') or chapter.get('number') or 0
                chapter_title = chapter.get('chapter_title') or chapter.get('title') or f"CapÃ­tulo {chapter_num}"
                safe_chapter_title = self._sanitize_filename(chapter_title)
                
                chapters_list += f"{chapter_num}. [[{chapter_num:03d} - {safe_chapter_title}|{chapter_title}]]\n"
            
            # ConteÃºdo do Ã­ndice
            content = f"""# {metadata.title}

## ğŸ‘¤ Autor
{metadata.author}

## ğŸ“Š InformaÃ§Ãµes
- **Total de pÃ¡ginas**: {metadata.total_pages}
- **Total de capÃ­tulos**: {len(chapters)}
- **ID do livro**: {book_id}
- **Processado em**: {datetime.now().strftime('%d/%m/%Y %H:%M')}

## ğŸ“‘ CapÃ­tulos
{chapters_list}

## ğŸ“ Notas Gerais
<!-- Adicione suas notas sobre o livro aqui -->

## ğŸ¯ Objetivos de Leitura
<!-- Defina seus objetivos de leitura -->

## ğŸ“… Progresso
| CapÃ­tulo | Data de Leitura | Status | Notas |
|----------|-----------------|--------|-------|
| 1 | | ğŸ“– Pendente | |
| 2 | | ğŸ“– Pendente | |
| ... | | ... | |
"""
            
            # Criar ou atualizar Ã­ndice
            existing_note = self.vault_manager.get_note_by_path(index_path)
            
            if existing_note:
                self.vault_manager.update_note(
                    index_path,
                    content=content,
                    frontmatter=frontmatter
                )
            else:
                self.vault_manager.create_note(
                    index_path,
                    content=content,
                    frontmatter=frontmatter
                )
            
            result["index_created"] = True
            
        except Exception as e:
            logger.error(f"Erro criando Ã­ndice: {e}")
            result["error"] = str(e)
        
        return result

    def create_single_note_structure(self, book_id: str, metadata, content: List[Dict], config: Dict = None) -> Dict:
        """Cria uma Ãºnica nota para todo o livro"""
        result = {
            "book_id": book_id,
            "directory_created": False,
            "notes_created": 0,
            "single_note": True,
            "errors": []
        }
        
        try:
            if not self.vault_manager:
                result["errors"].append("VaultManager nÃ£o disponÃ­vel")
                return result
            
            # Sanitizar nomes
            safe_author = self._resolve_author_directory_name(metadata.author or "Autor Desconhecido")
            safe_title = self._sanitize_filename(metadata.title)
            
            # Criar diretÃ³rio principal
            book_dir = self.vault_manager.vault_path / "01-LEITURAS" / safe_author / safe_title
            book_dir.mkdir(parents=True, exist_ok=True)
            result["directory_created"] = True
            result["directory_path"] = str(book_dir)
            
            # Combinar todo o conteÃºdo em uma Ãºnica string
            full_content = ""
            for chapter in content:
                chapter_num = chapter.get('chapter_num') or chapter.get('number') or 0
                chapter_title = chapter.get('chapter_title') or chapter.get('title') or f"CapÃ­tulo {chapter_num}"
                chapter_text = chapter.get('content', '')
                
                full_content += f"\n\n## CapÃ­tulo {chapter_num}: {chapter_title}\n\n"
                full_content += chapter_text
            
            # Caminho para a nota Ãºnica
            note_path = f"01-LEITURAS/{safe_author}/{safe_title}/ğŸ“š {safe_title} - Completo.md"
            
            # Frontmatter
            frontmatter = {
                'title': metadata.title,
                'book': metadata.title,
                'author': metadata.author,
                'type': 'livro_completo',
                'book_id': book_id,
                'total_pages': metadata.total_pages,
                'total_chapters': len(content),
                'processed_date': datetime.now().isoformat(),
                'tags': ['livro', 'nota_Ãºnica']
            }
            
            # Adicionar tags personalizadas se fornecidas
            if config and 'tags' in config:
                frontmatter['tags'].extend(config['tags'])
            
            # ConteÃºdo da nota
            note_content = f"""# {metadata.title}

## ğŸ‘¤ Autor
{metadata.author}

## ğŸ“Š InformaÃ§Ãµes
- **Total de pÃ¡ginas**: {metadata.total_pages}
- **Total de capÃ­tulos**: {len(content)}
- **Processado em**: {datetime.now().strftime('%d/%m/%Y %H:%M')}
- **ID do livro**: {book_id}

## ğŸ“ ConteÃºdo Completo
{full_content}

## ğŸ’­ AnotaÃ§Ãµes Pessoais
<!-- Adicione suas anotaÃ§Ãµes aqui -->

## ğŸ”— Ãndice de CapÃ­tulos
"""
            
            # Adicionar Ã­ndice
            for chapter in content:
                chapter_num = chapter.get('chapter_num') or chapter.get('number') or 0
                chapter_title = chapter.get('chapter_title') or chapter.get('title') or f"CapÃ­tulo {chapter_num}"
                note_content += f"{chapter_num}. {chapter_title}\n"
            
            existing_note = self.vault_manager.get_note_by_path(note_path)
            if existing_note:
                self.vault_manager.update_note(
                    note_path,
                    content=note_content,
                    frontmatter=frontmatter
                )
            else:
                self.vault_manager.create_note(
                    note_path,
                    content=note_content,
                    frontmatter=frontmatter
                )
            
            result["notes_created"] = 1
            
            # Emitir sinal
            self.book_structure_created.emit(book_id, result)
            
        except Exception as e:
            result["errors"].append(f"Erro criando nota Ãºnica: {e}")
            logger.error(f"Erro criando nota Ãºnica: {e}")
        
        return result
    
    def integrate_with_vault(self, book_id: str, metadata, chapters: List[Dict]) -> Dict:
        """Integra livro com o vault do Obsidian"""
        result = {
            "book_id": book_id,
            "success": False,
            "steps_completed": []
        }
        
        try:
            # 1. Criar estrutura
            structure_result = self.create_book_structure(book_id, metadata, chapters)
            if structure_result.get("directory_created"):
                result["steps_completed"].append("structure_created")
            
            # 2. Criar Ã­ndice
            index_result = self.create_book_index(book_id, metadata, chapters)
            if index_result.get("index_created"):
                result["steps_completed"].append("index_created")
            
            # 3. Criar nota de conceitos
            concepts_result = self._create_concepts_note(book_id, metadata)
            if concepts_result.get("concepts_note_created"):
                result["steps_completed"].append("concepts_note_created")
            
            result["success"] = len(result["steps_completed"]) > 0
            result["details"] = {
                "structure": structure_result,
                "index": index_result,
                "concepts": concepts_result
            }
            
        except Exception as e:
            result["error"] = str(e)
            logger.error(f"Erro na integraÃ§Ã£o com vault: {e}")
        
        return result
    
    def _create_concepts_note(self, book_id: str, metadata) -> Dict:
        """Cria nota de conceitos-chave do livro"""
        result = {"concepts_note_created": False}
        
        try:
            if not self.vault_manager:
                return result
            
            safe_author = self._resolve_author_directory_name(metadata.author or "Autor Desconhecido")
            safe_title = self._sanitize_filename(metadata.title)
            
            # Caminho para a nota de conceitos
            concepts_path = f"01-LEITURAS/{safe_author}/{safe_title}/ğŸ§  Conceitos-Chave.md"
            
            # Frontmatter
            frontmatter = {
                'title': f'Conceitos-Chave - {metadata.title}',
                'book': metadata.title,
                'author': metadata.author,
                'type': 'concepts',
                'book_id': book_id,
                'tags': ['conceitos', 'livro']
            }
            
            # ConteÃºdo da nota
            content = f"""# Conceitos-Chave - {metadata.title}

## ğŸ“š Livro
[[{metadata.title}]]

## ğŸ§  Conceitos Principais
<!-- Liste e explique os conceitos principais do livro aqui -->

## ğŸ’¬ CitaÃ§Ãµes Importantes
<!-- Colete citaÃ§Ãµes importantes do livro -->

## â“ QuestÃµes para ReflexÃ£o
<!-- QuestÃµes geradas pela LLM ou suas prÃ³prias -->

## ğŸ” ConexÃµes com Outras Obras
<!-- Relacione com outros livros ou autores -->

## ğŸ“ Minhas ReflexÃµes
<!-- Adicione suas prÃ³prias reflexÃµes -->
"""
            
            # Criar nota
            self.vault_manager.create_note(
                concepts_path,
                content=content,
                frontmatter=frontmatter
            )
            
            result["concepts_note_created"] = True
            
        except Exception as e:
            result["error"] = str(e)
        
        return result
    
    def register_book_in_system(self, book_id: str, title: str, author: str, 
                               total_pages: int, file_path: Path) -> Dict:
        """Registra livro em todos os sistemas necessÃ¡rios"""
        result = {
            "book_id": book_id,
            "success": False,
            "systems_registered": [],
            "errors": []
        }
        
        try:
            # 1. Registrar no ReadingManager
            if self.reading_manager:
                try:
                    # Verificar se jÃ¡ existe
                    existing = self.reading_manager.get_reading_progress(book_id)
                    
                    if not existing:
                        # Adicionar novo livro
                        added_id = self.reading_manager.add_book(
                            title=title,
                            author=author,
                            total_pages=total_pages,
                            book_id=book_id
                        )
                        
                        if added_id:
                            result["systems_registered"].append("reading_manager")
                            result["reading_system_id"] = added_id
                            logger.info(f"Livro {book_id} registrado no ReadingManager")
                        else:
                            result["errors"].append("Falha ao adicionar ao ReadingManager")
                    else:
                        result["systems_registered"].append("reading_manager (existing)")
                        logger.info(f"Livro {book_id} jÃ¡ existe no ReadingManager")
                        
                except Exception as e:
                    result["errors"].append(f"ReadingManager error: {str(e)}")
                    logger.error(f"Erro no ReadingManager para {book_id}: {e}")
            
            # 2. Registrar no cache interno
            self.book_registry[book_id] = {
                "title": title,
                "author": author,
                "total_pages": total_pages,
                "file_path": str(file_path),
                "registered_at": datetime.now().isoformat(),
                "systems": result["systems_registered"]
            }
            
            # 3. Registrar no vault (se disponÃ­vel)
            if self.vault_manager:
                try:
                    # Criar nota de registro no vault
                    registry_path = f"06-RECURSOS/registros_livros/{book_id}.json"
                    
                    registry_data = {
                        "book_id": book_id,
                        "title": title,
                        "author": author,
                        "total_pages": total_pages,
                        "file_path": str(file_path),
                        "registered_at": datetime.now().isoformat(),
                        "processing_complete": True
                    }
                    
                    # Criar diretÃ³rio se nÃ£o existir
                    registry_dir = self.vault_manager.vault_path / "06-RECURSOS" / "registros_livros"
                    registry_dir.mkdir(parents=True, exist_ok=True)
                    
                    # Salvar JSON
                    registry_file = registry_dir / f"{book_id}.json"
                    with open(registry_file, 'w', encoding='utf-8') as f:
                        json.dump(registry_data, f, indent=2, ensure_ascii=False)
                    
                    result["systems_registered"].append("vault_registry")
                    
                except Exception as e:
                    result["errors"].append(f"VaultRegistry error: {str(e)}")
            
            # Verificar sucesso
            if len(result["systems_registered"]) > 0:
                result["success"] = True
                result["status"] = "registered"
                
                # Emitir sinal de registro
                self.book_registered.emit(book_id, result)
                
            else:
                result["status"] = "registration_failed"
                
        except Exception as e:
            result["errors"].append(f"Registration error: {str(e)}")
            logger.error(f"Erro geral no registro do livro {book_id}: {e}")
        
        return result
    
    def schedule_book_reading(self, book_id: str, title: str = None, 
                             total_pages: int = None) -> Dict:
        """Agenda leitura automÃ¡tica do livro"""
        result = {
            "book_id": book_id,
            "success": False,
            "scheduling_attempted": False,
            "agenda_events_created": 0,
            "error": None
        }
        
        try:
            # Verificar se temos AgendaController
            if not self.agenda_controller:
                result["error"] = "AgendaController nÃ£o disponÃ­vel"
                return result
            
            # Obter informaÃ§Ãµes do livro (se nÃ£o fornecidas)
            if not title or not total_pages:
                book_info = self.get_book_info(book_id)
                if not book_info:
                    result["error"] = f"Livro {book_id} nÃ£o encontrado"
                    return result
                
                title = book_info.get("title", title)
                total_pages = book_info.get("total_pages", total_pages)
                author = book_info.get("author", "Desconhecido")
            else:
                author = self.book_registry.get(book_id, {}).get("author", "Desconhecido")

            # Sincroniza o livro no ReadingManager usado pela camada de agenda.
            self._sync_book_to_agenda_reading_manager(
                book_id=book_id,
                title=title,
                author=author,
                total_pages=total_pages
            )
            
            # Calcular pÃ¡ginas por dia
            pages_per_day = self._calculate_pages_per_day(total_pages)
            
            # Chamar AgendaController para alocar tempo
            result["scheduling_attempted"] = True
            result["pages_per_day"] = pages_per_day
            result["strategy"] = self.default_scheduling_strategy
            
            # Usar mÃ©todo sÃ­ncrono para garantir execuÃ§Ã£o
            scheduling_result = self._execute_scheduling(
                book_id=book_id,
                pages_per_day=pages_per_day,
                strategy=self.default_scheduling_strategy
            )
            
            # Processar resultado
            if "error" in scheduling_result:
                result["error"] = scheduling_result["error"]
            else:
                result["success"] = True
                result["agenda_events_created"] = scheduling_result.get("total_sessions", 0)
                result["allocation_details"] = scheduling_result
                
                # Emitir sinal de agendamento
                self.book_scheduled.emit(book_id, result)
                
                logger.info(f"Leitura agendada para {book_id}: {pages_per_day} pÃ¡ginas/dia")
        
        except Exception as e:
            result["error"] = str(e)
            logger.error(f"Erro no agendamento de {book_id}: {e}")
        
        return result

    def _get_agenda_reading_manager(self):
        """Retorna o ReadingManager efetivo usado pelo agendador."""
        if not self.agenda_controller:
            return None
        if hasattr(self.agenda_controller, "reading_manager"):
            return self.agenda_controller.reading_manager
        if hasattr(self.agenda_controller, "agenda_manager"):
            agenda_manager = getattr(self.agenda_controller, "agenda_manager", None)
            if agenda_manager and hasattr(agenda_manager, "reading_manager"):
                return agenda_manager.reading_manager
        return None

    def _sync_book_to_agenda_reading_manager(self, book_id: str, title: str,
                                             author: str, total_pages: int):
        """
        Garante que o livro exista no ReadingManager consultado pelo agendador.
        Evita erro de "Livro nÃ£o encontrado" apÃ³s importaÃ§Ã£o recÃ©m-concluÃ­da.
        """
        agenda_reading_manager = self._get_agenda_reading_manager()
        if not agenda_reading_manager:
            return

        try:
            agenda_progress = agenda_reading_manager.get_reading_progress(book_id)
            if agenda_progress:
                return

            source_progress = None
            if self.reading_manager and hasattr(self.reading_manager, "readings"):
                source_progress = self.reading_manager.readings.get(book_id)

            if source_progress is not None and hasattr(agenda_reading_manager, "readings"):
                agenda_reading_manager.readings[book_id] = source_progress
                if hasattr(agenda_reading_manager, "_save_progress"):
                    agenda_reading_manager._save_progress()
                return

            if hasattr(agenda_reading_manager, "add_book"):
                agenda_reading_manager.add_book(
                    title=title or "Desconhecido",
                    author=author or "Desconhecido",
                    total_pages=int(total_pages or 0),
                    book_id=book_id
                )
        except Exception as e:
            logger.warning(f"NÃ£o foi possÃ­vel sincronizar livro {book_id} para agenda: {e}")
    
    def _execute_scheduling(self, book_id: str, pages_per_day: float, strategy: str) -> Dict:
        """Executa agendamento de forma sÃ­ncrona com fallback"""
        try:
            # Usar mÃ©todo sÃ­ncrono do AgendaController
            if hasattr(self.agenda_controller, 'allocate_reading_time'):
                return self.agenda_controller.allocate_reading_time(
                    book_id=book_id,
                    pages_per_day=pages_per_day,
                    strategy=strategy
                )
            elif hasattr(self.agenda_controller, 'allocate_reading_time_async'):
                # Se for assÃ­ncrono, usar QEventLoop para sincronizar
                from PyQt6.QtCore import QEventLoop
                
                result_container = {"result": None}
                event_loop = QEventLoop()
                
                def on_allocation_result(allocation_result):
                    result_container["result"] = allocation_result
                    event_loop.quit()
                
                # Conectar sinal temporariamente
                self.agenda_controller.reading_allocated.connect(on_allocation_result)
                
                # Iniciar agendamento
                self.agenda_controller.allocate_reading_time_async(
                    book_id, pages_per_day, strategy
                )
                
                # Aguardar resultado (timeout de 10 segundos)
                QTimer.singleShot(10000, event_loop.quit)
                event_loop.exec()
                
                # Desconectar sinal
                self.agenda_controller.reading_allocated.disconnect(on_allocation_result)
                
                return result_container.get("result", {"error": "Timeout no agendamento"})
            
            else:
                return {"error": "MÃ©todo de agendamento nÃ£o disponÃ­vel"}
                
        except Exception as e:
            logger.error(f"Erro na execuÃ§Ã£o do agendamento: {e}")
            return {"error": str(e)}
    
    def _calculate_pages_per_day(self, total_pages: int) -> float:
        """Calcula pÃ¡ginas por dia de forma inteligente"""
        if total_pages <= 0:
            return self.default_pages_per_day
        
        # Baseado no total de pÃ¡ginas e complexidade estimada
        if total_pages < 100:
            return 15  # Livro curto
        elif total_pages < 300:
            return 12  # Livro mÃ©dio
        elif total_pages < 600:
            return 10  # Livro longo
        else:
            return 8   # Livro muito longo
    
    # ====== CALLBACKS DO PIPELINE ======
    
    def _on_stage_started(self, pipeline_id: str, stage: str, message: str):
        """Chamado quando um estÃ¡gio do pipeline inicia"""
        logger.info(f"Pipeline {pipeline_id} - {stage}: {message}")
    
    def _on_stage_progress(self, pipeline_id: str, stage: str, percent: int, message: str):
        """Chamado durante progresso de um estÃ¡gio"""
        # Emitir sinal de progresso para a UI
        self.book_processing_progress.emit(pipeline_id, stage, percent, message)
        logger.debug(f"Pipeline {pipeline_id} - {stage}: {percent}% - {message}")
    
    def _on_stage_completed(self, pipeline_id: str, stage: str, result: dict):
        """Chamado quando um estÃ¡gio Ã© concluÃ­do"""
        logger.info(f"Pipeline {pipeline_id} - {stage} concluÃ­do")
        
        # AÃ§Ãµes especÃ­ficas por estÃ¡gio
        if stage == "integration" and result.get("book_id"):
            book_id = result["book_id"]
            logger.info(f"Pipeline {pipeline_id} - Livro {book_id} integrado com sucesso")
    
    def _on_stage_failed(self, pipeline_id: str, stage: str, error: str):
        """Chamado quando um estÃ¡gio falha"""
        logger.error(f"Pipeline {pipeline_id} - Falha em {stage}: {error}")
        # NÃ£o interrompemos o pipeline aqui, deixamos ele lidar
    
    def _on_pipeline_completed(self, pipeline_id: str, result: dict):
        """Chamado quando o pipeline Ã© concluÃ­do com sucesso"""
        # Limpar pipeline da lista ativa
        self.pipeline_mutex.lock()
        try:
            if pipeline_id in self.active_pipelines:
                pipeline = self.active_pipelines[pipeline_id]
                pipeline.wait(1000)
                del self.active_pipelines[pipeline_id]
        finally:
            self.pipeline_mutex.unlock()
        
        # Emitir sinal de conclusÃ£o
        self.book_processing_completed.emit(pipeline_id, result)
        
        logger.info(f"Pipeline {pipeline_id} concluÃ­do: {result.get('title', 'Desconhecido')}")
    
    def _on_pipeline_failed(self, pipeline_id: str, error: str):
        """Chamado quando o pipeline falha"""
        # Limpar pipeline da lista ativa
        self.pipeline_mutex.lock()
        try:
            if pipeline_id in self.active_pipelines:
                pipeline = self.active_pipelines[pipeline_id]
                pipeline.stop()
                del self.active_pipelines[pipeline_id]
        finally:
            self.pipeline_mutex.unlock()
        
        # Emitir sinal de falha
        self.book_processing_failed.emit(pipeline_id, error)
        
        logger.error(f"Pipeline {pipeline_id} falhou: {error}")
    
    # ====== MÃ‰TODOS AUXILIARES ======
    
    def get_book_info(self, book_id: str) -> Optional[Dict]:
        """ObtÃ©m informaÃ§Ãµes do livro do cache interno"""
        # Primeiro, verificar cache interno
        if book_id in self.book_registry:
            return self.book_registry[book_id]
        
        # Depois, verificar ReadingManager
        if self.reading_manager:
            try:
                progress = self.reading_manager.get_reading_progress(book_id)
                if progress:
                    return {
                        "book_id": book_id,
                        "title": progress.get("title"),
                        "author": progress.get("author", "Desconhecido"),
                        "total_pages": progress.get("total_pages", 0),
                        "current_page": progress.get("current_page", 0),
                        "source": "reading_manager"
                    }
            except Exception as e:
                logger.error(f"Erro ao obter info do ReadingManager: {e}")
        
        return None
    
    
    @pyqtSlot(dict, result=str)
    def process_book_with_config(self, config: dict) -> str:
        """
        Processa livro com configuraÃ§Ãµes avanÃ§adas
        
        Args:
            config: DicionÃ¡rio com todas as configuraÃ§Ãµes:
                - file_path: caminho do arquivo
                - quality: qualidade do processamento
                - use_llm: usar LLM para aprimoramento
                - auto_schedule: agendar automaticamente
                - metadata: metadados editados
                - notes_config: configuraÃ§Ãµes de notas
                - scheduling_config: configuraÃ§Ãµes de agendamento
                
        Returns:
            pipeline_id: ID do pipeline
        """
        try:
            # Extrair configuraÃ§Ãµes bÃ¡sicas
            file_path = config.get("file_path")
            quality = config.get("quality", self.default_quality)
            use_llm = config.get("use_llm", self.default_use_llm)
            auto_schedule = config.get("auto_schedule", self.auto_schedule_reading)
            
            # Validar arquivo
            if not Path(file_path).exists():
                raise FileNotFoundError(f"Arquivo nÃ£o encontrado: {file_path}")
            
            # Criar pipeline com configuraÃ§Ãµes estendidas
            pipeline = BookProcessingPipeline(
                controller=self,
                file_path=file_path,
                quality=quality,
                schedule_reading=auto_schedule,
                use_llm=use_llm,
                config=config  # Passar configuraÃ§Ãµes completas
            )
            
            pipeline_id = pipeline.pipeline_id
            
            # Registrar pipeline ativo
            self.pipeline_mutex.lock()
            try:
                self.active_pipelines[pipeline_id] = pipeline
            finally:
                self.pipeline_mutex.unlock()
            
            # Conectar sinais do pipeline
            pipeline.stage_started.connect(self._on_stage_started)
            pipeline.stage_progress.connect(self._on_stage_progress)
            pipeline.stage_completed.connect(self._on_stage_completed)
            pipeline.stage_failed.connect(self._on_stage_failed)
            pipeline.pipeline_completed.connect(self._on_pipeline_completed)
            pipeline.pipeline_failed.connect(self._on_pipeline_failed)
            
            # Iniciar pipeline
            pipeline.start()
            
            # Emitir sinal de inÃ­cio
            file_name = Path(file_path).stem
            settings = {
                "file_path": file_path,
                "quality": quality,
                "use_llm": use_llm,
                "auto_schedule": auto_schedule,
                "config": config,
                "timestamp": datetime.now().isoformat()
            }
            self.book_processing_started.emit(pipeline_id, file_name, settings)
            
            logger.info(f"Pipeline {pipeline_id} iniciado com configuraÃ§Ãµes avanÃ§adas")
            
            return pipeline_id
            
        except Exception as e:
            logger.error(f"Erro ao iniciar processamento com configuraÃ§Ãµes: {e}")
            raise
    
    def update_book_metadata(self, pipeline_id: str, metadata: dict):
        """Atualizar metadados de um livro em processamento"""
        if pipeline_id in self.active_pipelines:
            pipeline = self.active_pipelines[pipeline_id]
            if hasattr(pipeline, 'metadata'):
                # Atualizar metadados do pipeline
                for key, value in metadata.items():
                    if hasattr(pipeline.metadata, key):
                        setattr(pipeline.metadata, key, value)
                    else:
                        # Adicionar atributo dinÃ¢mico se nÃ£o existir
                        setattr(pipeline.metadata, key, value)

    def save_to_history(self, result: Dict):
        """Salva resultado no histÃ³rico"""
        self.processing_history.append({
            "timestamp": datetime.now().isoformat(),
            "result": result
        })
        
        # Manter apenas os Ãºltimos 100 registros
        if len(self.processing_history) > 100:
            self.processing_history = self.processing_history[-100:]
    
    def get_processing_history(self, limit: int = 20) -> List[Dict]:
        """Retorna histÃ³rico de processamento"""
        return self.processing_history[-limit:] if self.processing_history else []
    
    def _sanitize_filename(self, filename: str) -> str:
        """Sanitiza nome de arquivo"""
        # Substituir caracteres problemÃ¡ticos
        filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
        filename = re.sub(r'\s+', ' ', filename).strip()
        return filename[:100]  # Limitar tamanho

    def _normalize_path_key(self, value: str) -> str:
        """Normaliza texto para comparaÃ§Ã£o estÃ¡vel de nomes de pastas."""
        normalized = unicodedata.normalize("NFKD", value or "")
        normalized = "".join(ch for ch in normalized if not unicodedata.combining(ch))
        normalized = re.sub(r"[^a-zA-Z0-9]+", " ", normalized).strip().lower()
        return re.sub(r"\s+", " ", normalized)

    def _primary_author(self, author_name: str) -> str:
        """Extrai autor principal para evitar duplicaÃ§Ãµes por coautoria/formato."""
        raw = (author_name or "").strip()
        if not raw:
            return "Autor Desconhecido"

        # Separadores comuns de mÃºltiplos autores.
        split_patterns = [r"\s*&\s*", r"\s+and\s+", r"\s+e\s+", r"\s*;\s*", r"\s*/\s*", r"\s*\|\s*"]
        for pattern in split_patterns:
            parts = re.split(pattern, raw, maxsplit=1, flags=re.IGNORECASE)
            if parts and parts[0].strip() and len(parts) > 1:
                raw = parts[0].strip()
                break

        # "Sobrenome, Nome" -> "Nome Sobrenome"
        if "," in raw:
            fragments = [frag.strip() for frag in raw.split(",") if frag.strip()]
            if len(fragments) >= 2:
                raw = f"{fragments[1]} {fragments[0]}".strip()

        return raw

    def _author_tokens(self, author_name: str) -> set[str]:
        """Tokeniza nome de autor para comparaÃ§Ã£o por similaridade."""
        normalized = self._normalize_path_key(self._primary_author(author_name))
        tokens = {tok for tok in normalized.split(" ") if len(tok) > 1}
        return tokens

    def _soft_token_overlap(self, left_tokens: set[str], right_tokens: set[str]) -> float:
        """
        SobreposiÃ§Ã£o fuzzy de tokens para capturar pequenas variaÃ§Ãµes ortogrÃ¡ficas.
        Ex.: guatarri ~= guattari.
        """
        if not left_tokens or not right_tokens:
            return 0.0

        right_list = list(right_tokens)
        used = set()
        matched = 0

        for token in left_tokens:
            best_idx = None
            best_ratio = 0.0
            for idx, candidate in enumerate(right_list):
                if idx in used:
                    continue
                ratio = SequenceMatcher(None, token, candidate).ratio()
                if ratio > best_ratio:
                    best_ratio = ratio
                    best_idx = idx

            if best_idx is not None and best_ratio >= 0.84:
                used.add(best_idx)
                matched += 1

        return matched / max(len(left_tokens), len(right_tokens))

    def _resolve_author_directory_name(self, author_name: str) -> str:
        """
        Reutiliza diretÃ³rio existente do autor, evitando duplicatas por acento/caixa/pontuaÃ§Ã£o.
        """
        canonical_author = self._primary_author(author_name or "Autor Desconhecido")
        safe_author = self._sanitize_filename(canonical_author)
        if not self.vault_manager:
            return safe_author

        authors_root = self.vault_manager.vault_path / "01-LEITURAS"
        if not authors_root.exists():
            return safe_author

        target_key = self._normalize_path_key(canonical_author)
        target_tokens = self._author_tokens(canonical_author)
        if not target_key:
            return safe_author

        best_match_name = None
        best_score = 0.0

        try:
            for child in authors_root.iterdir():
                if not child.is_dir():
                    continue

                child_key = self._normalize_path_key(child.name)
                if child_key == target_key:
                    return child.name

                child_tokens = self._author_tokens(child.name)
                if not target_tokens or not child_tokens:
                    continue

                intersection = len(target_tokens & child_tokens)
                union = len(target_tokens | child_tokens)
                jaccard_score = (intersection / union) if union else 0.0
                fuzzy_score = self._soft_token_overlap(target_tokens, child_tokens)
                score = max(jaccard_score, fuzzy_score)

                if score > best_score:
                    best_score = score
                    best_match_name = child.name
        except Exception:
            return safe_author

        if best_match_name and best_score >= 0.8:
            return best_match_name

        return safe_author
    
    def _perform_maintenance(self):
        """Executa manutenÃ§Ã£o periÃ³dica"""
        try:
            # Limpar pipelines finalizados
            pipelines_to_remove = []
            
            for pipeline_id, pipeline in list(self.active_pipelines.items()):
                if not pipeline.isRunning():
                    pipelines_to_remove.append(pipeline_id)
            
            for pipeline_id in pipelines_to_remove:
                if pipeline_id in self.active_pipelines:
                    del self.active_pipelines[pipeline_id]
            
            # Limpar cache antigo (mais de 1 hora)
            current_time = datetime.now()
            old_keys = []
            
            for key, entry in list(self.book_registry.items()):
                if "registered_at" in entry:
                    try:
                        registered_time = datetime.fromisoformat(entry["registered_at"])
                        if (current_time - registered_time).total_seconds() > 3600:
                            old_keys.append(key)
                    except:
                        old_keys.append(key)
            
            for key in old_keys:
                del self.book_registry[key]
            
            # Salvar histÃ³rico em arquivo
            self._save_history_to_file()
            
            logger.debug(f"ManutenÃ§Ã£o executada: {len(pipelines_to_remove)} pipelines limpos")
            
        except Exception as e:
            logger.error(f"Erro na manutenÃ§Ã£o: {e}")
    
    def _save_history_to_file(self):
        """Salva histÃ³rico em arquivo"""
        try:
            history_dir = Path("./data/history")
            history_dir.mkdir(parents=True, exist_ok=True)
            
            history_file = history_dir / "book_processing_history.json"
            
            with open(history_file, 'w', encoding='utf-8') as f:
                json.dump({
                    "last_updated": datetime.now().isoformat(),
                    "history": self.processing_history[-50:]  # Ãšltimos 50 registros
                }, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            logger.error(f"Erro salvando histÃ³rico: {e}")
    
    @pyqtSlot(str)
    def cancel_processing(self, pipeline_id: str):
        """Cancela um pipeline em andamento"""
        self.pipeline_mutex.lock()
        try:
            if pipeline_id in self.active_pipelines:
                pipeline = self.active_pipelines[pipeline_id]
                pipeline.stop()
                del self.active_pipelines[pipeline_id]
                logger.info(f"Pipeline {pipeline_id} cancelado")
        finally:
            self.pipeline_mutex.unlock()
    
    @pyqtSlot(str, result=dict)
    def get_processing_status(self, pipeline_id: str) -> Dict:
        """Retorna status de um pipeline"""
        if pipeline_id in self.active_pipelines:
            pipeline = self.active_pipelines[pipeline_id]
            return {
                "pipeline_id": pipeline_id,
                "is_running": pipeline.isRunning(),
                "current_stage": pipeline._current_stage.value if pipeline._current_stage else None,
                "book_id": pipeline.book_id,
                "has_metadata": pipeline.metadata is not None
            }
        return {"pipeline_id": pipeline_id, "status": "not_found"}
    
    def cleanup(self):
        """Limpeza antes de encerrar"""
        # Parar todos os pipelines
        for pipeline_id, pipeline in list(self.active_pipelines.items()):
            pipeline.stop()
        
        # Parar timer
        self.maintenance_timer.stop()
        
        # Salvar histÃ³rico
        self._save_history_to_file()
        
        logger.info("BookController finalizado")
