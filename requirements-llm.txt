# Dependências principais para o módulo LLM
llama-cpp-python>=0.2.0
python-frontmatter>=1.0.0
PyYAML>=6.0.0
rich>=13.0.0

# Processamento de texto básico (já incluso, sem CUDA)
numpy>=1.24.0

# Para desenvolvimento
pytest>=7.0.0

# NENHUMA DEPENDÊNCIA DE: sentence-transformers, torch, tensorflow, CUDA
