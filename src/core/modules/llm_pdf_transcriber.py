# src/core/modules/llm_pdf_processor.py
"""
Processamento de PDFs usando a LLM local do GLaDOS
"""
import logging
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
import fitz  # PyMuPDF
from dataclasses import dataclass, field
from datetime import datetime
import hashlib

from .book_processor import BookMetadata, ProcessingResult, ProcessingStatus
from .obsidian.vault_manager import ObsidianVaultManager

logger = logging.getLogger(__name__)

@dataclass
class PDFPage:
    """Representa uma p√°gina de PDF processada."""
    page_num: int
    text: str
    confidence: float = 1.0
    requires_llm: bool = False
    llm_processed: bool = False
    hash: str = ""

class LLMPDFProcessor:
    """Processador de PDFs usando LLM local do GLaDOS."""
    
    def __init__(self, llm_instance=None, vault_manager: Optional[ObsidianVaultManager] = None):
        """
        Inicializa com a LLM local do GLaDOS.
        
        Args:
            llm_instance: Inst√¢ncia da LLM (se None, tenta importar)
            vault_manager: Gerenciador do vault
        """
        self.llm = llm_instance
        self.vault_manager = vault_manager or ObsidianVaultManager()
        self.page_cache = {}
        
        # Tenta importar a LLM se n√£o foi fornecida
        if self.llm is None:
            try:
                # Importa√ß√£o ABSOLUTA da LLM do GLaDOS
                from src.core.llm.local_llm import llm as glados_llm
                self.llm = glados_llm
                logger.info("‚úÖ LLM do GLaDOS carregada com sucesso")
            except ImportError as e:
                logger.warning(f"‚ö†Ô∏è  N√£o foi poss√≠vel importar a LLM do GLaDOS: {e}")
                logger.info("üìö Usando apenas extra√ß√£o b√°sica de texto")
        
        logger.info(f"LLMPDFProcessor inicializado (LLM: {self.llm is not None})")
    
    def extract_page_text(self, pdf_path: str, page_num: int) -> str:
        """
        Extrai texto de uma p√°gina do PDF.
        
        Args:
            pdf_path: Caminho do PDF
            page_num: N√∫mero da p√°gina (0-index)
            
        Returns:
            Texto extra√≠do
        """
        try:
            doc = fitz.open(pdf_path)
            page = doc.load_page(page_num)
            text = page.get_text()
            doc.close()
            
            return text
        except Exception as e:
            logger.error(f"Erro extraindo p√°gina {page_num}: {e}")
            return ""
    
    def process_page_with_llm(self, pdf_path: str, page_num: int, 
                            metadata: BookMetadata) -> str:
        """
        Processa uma p√°gina do PDF usando LLM do GLaDOS.
        
        Args:
            pdf_path: Caminho do PDF
            page_num: N√∫mero da p√°gina
            metadata: Metadados do livro
            
        Returns:
            Texto processado pela LLM
        """
        try:
            # Primeiro, tenta extrair texto normalmente
            text = self.extract_page_text(pdf_path, page_num)
            
            # Se extraiu texto suficiente, retorna
            if len(text.strip()) > 100:
                logger.debug(f"P√°gina {page_num+1}: Texto extra√≠do normalmente ({len(text)} chars)")
                return text
            
            # Se pouco texto, usa LLM para melhorar
            if self.llm and hasattr(self.llm, 'generate'):
                logger.info(f"P√°gina {page_num+1} usando LLM para melhorar extra√ß√£o")
                
                # Cria prompt para a LLM
                prompt = self._create_llm_prompt(text, metadata, page_num)
                
                # Usa a LLM do GLaDOS
                response = self.llm.generate(prompt, use_semantic=False)
                
                if response and "text" in response:
                    llm_text = response["text"]
                    logger.debug(f"LLM retornou {len(llm_text)} caracteres")
                    
                    # Combina o texto original com a melhoria da LLM
                    if len(text.strip()) > 0:
                        # Se tinha algum texto, mant√©m e adiciona a melhoria
                        combined = f"{text}\n\n--- Melhoria da LLM ---\n\n{llm_text}"
                    else:
                        combined = llm_text
                    
                    return combined
                else:
                    logger.warning("LLM n√£o retornou texto v√°lido")
                    return f"[P√°gina {page_num+1}: Falha na melhoria com LLM]\n{text}"
            else:
                logger.debug(f"LLM n√£o dispon√≠vel para p√°gina {page_num+1}")
                return text if text else f"[P√°gina {page_num+1}: Sem texto extra√≠do]"
                
        except Exception as e:
            logger.error(f"Erro processando p√°gina {page_num} com LLM: {e}")
            return f"[ERRO LLM: {str(e)[:100]}]\n{text if 'text' in locals() else ''}"
    
    # Adicione este m√©todo √† classe LLMPDFProcessor

    def process_chapter_range(self, pdf_path: str, start_page: int, end_page: int,
                             metadata: BookMetadata, chapter_num: int = None) -> Dict:
        """
        Processa um intervalo espec√≠fico de p√°ginas como um cap√≠tulo
    
        Args:
            pdf_path: Caminho do PDF
            start_page: P√°gina inicial (0-index)
            end_page: P√°gina final (0-index)
            metadata: Metadados do livro
            chapter_num: N√∫mero do cap√≠tulo
        
        Returns:
            Resultado do processamento
        """
        try:
            import fitz
        
            doc = fitz.open(pdf_path)
            chapter_text = ""
        
            # Garante que as p√°ginas est√£o dentro dos limites
            start_page = max(0, start_page)
            end_page = min(len(doc) - 1, end_page)
        
            print(f"üìÑ Processando p√°ginas {start_page+1} a {end_page+1}")
        
            for page_num in range(start_page, end_page + 1):
                if page_num >= len(doc):
                    break
                
                print(f"  P√°gina {page_num+1}/{len(doc)}")
            
                # Extrai texto
                text = self.extract_page_text(pdf_path, page_num)
            
                # Usa LLM se texto insuficiente
                if len(text.strip()) < 100 and self.llm:
                    text = self.process_page_with_llm(pdf_path, page_num, metadata)
            
                chapter_text += f"\n\n--- P√°gina {page_num + 1} ---\n\n{text}"
        
            doc.close()
        
            # Detecta t√≠tulo do cap√≠tulo
            lines = chapter_text.strip().split('\n')
            chapter_title = f"Cap√≠tulo {chapter_num}" if chapter_num else "Cap√≠tulo"
        
            for line in lines[:10]:
                line = line.strip()
                if (len(line) > 30 and len(line) < 200 and 
                    not line.startswith('---') and
                    not re.match(r'^\d+$', line)):
                
                    # Remove caracteres especiais do in√≠cio
                    clean_line = re.sub(r'^[^a-zA-Z0-9]*', '', line)
                    if clean_line and len(clean_line) > 10:
                        chapter_title = clean_line[:100]
                        break
        
            return {
                'success': True,
                'chapter_num': chapter_num,
                'chapter_title': chapter_title,
                'start_page': start_page + 1,
                'end_page': end_page + 1,
                'num_pages': (end_page - start_page + 1),
                'content': chapter_text,
                'content_length': len(chapter_text)
            }
        
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'chapter_num': chapter_num
            }

    def _create_llm_prompt(self, extracted_text: str, metadata: BookMetadata, 
                          page_num: int) -> str:
        """Cria prompt para a LLM melhorar texto extra√≠do."""
        # Se tem pouco texto, pede para a LLM tentar reconstruir
        if len(extracted_text.strip()) < 50:
            return f"""Voc√™ √© um assistente filos√≥fico especializado em Dostoi√©vski.

Livro: {metadata.title}
Autor: {metadata.author}
P√°gina: {page_num + 1}

TEXTO EXTRA√çDO (muito curto ou incompleto):
"{extracted_text}"

Com base no contexto do livro e no estilo de Dostoi√©vski, escreva o que provavelmente estaria nesta p√°gina.

Considere:
1. O estilo denso e psicol√≥gico de Dostoi√©vski
2. Temas de culpa, reden√ß√£o e moralidade
3. Contexto de "Crime e Castigo"

Forne√ßa uma reconstru√ß√£o plaus√≠vel desta p√°gina."""
        else:
            return f"""Voc√™ √© um assistente especializado em processamento de textos filos√≥ficos.

LIVRO: {metadata.title}
AUTOR: {metadata.author}
P√ÅGINA: {page_num + 1}

TEXTO EXTRA√çDO (pode ter problemas de formata√ß√£o ou OCR):

INSTRU√á√ïES:
1. Corrija erros √≥bvios de formata√ß√£o
2. Organize em par√°grafos l√≥gicos
3. Melhore a pontua√ß√£o se necess√°rio
4. Mantenha o significado filos√≥fico original
5. Se algo estiver ileg√≠vel, marque como "[...]"
6. Preserve qualquer termo filos√≥fico espec√≠fico

Responda APENAS com o texto corrigido, sem coment√°rios adicionais."""
    
    def process_book(self, pdf_path: str, metadata: BookMetadata,
                    output_dir: Path, max_pages: int = None) -> Dict[str, Any]:
        """
        Processa um livro completo usando LLM.
        
        Args:
            pdf_path: Caminho do PDF
            metadata: Metadados do livro
            output_dir: Diret√≥rio de sa√≠da
            max_pages: N√∫mero m√°ximo de p√°ginas a processar
            
        Returns:
            Resultados do processamento
        """
        logger.info(f"Processando livro '{metadata.title}' com LLM")
        
        try:
            doc = fitz.open(pdf_path)
            total_pages = len(doc)
            
            if max_pages:
                pages_to_process = min(max_pages, total_pages)
                logger.info(f"Limitado a {pages_to_process}/{total_pages} p√°ginas")
            else:
                pages_to_process = total_pages
            
            processed_pages = []
            
            for page_num in range(pages_to_process):
                logger.info(f"Processando p√°gina {page_num+1}/{pages_to_process}")
                
                # Tenta extrair texto normalmente primeiro
                text = self.extract_page_text(pdf_path, page_num)
                
                # Decide se precisa de LLM
                needs_llm = len(text.strip()) < 100  # Pouco texto
                
                if needs_llm and self.llm:
                    logger.debug(f"P√°gina {page_num+1} usando LLM")
                    text = self.process_page_with_llm(pdf_path, page_num, metadata)
                elif needs_llm:
                    logger.debug(f"P√°gina {page_num+1} precisa de LLM mas n√£o dispon√≠vel")
                
                # Calcula hash do conte√∫do
                content_hash = hashlib.md5(text.encode()).hexdigest()
                
                processed_pages.append(PDFPage(
                    page_num=page_num + 1,
                    text=text,
                    confidence=0.9 if not needs_llm else 0.7,
                    requires_llm=needs_llm,
                    llm_processed=needs_llm and self.llm is not None,
                    hash=content_hash
                ))
                
                # Pequena pausa para n√£o sobrecarregar
                import time
                if needs_llm and self.llm:
                    time.sleep(0.5)  # 500ms entre p√°ginas com LLM
            
            doc.close()
            
            # Organiza em cap√≠tulos
            chapters = self._organize_into_chapters(processed_pages, metadata, output_dir)
            
            # Estat√≠sticas
            llm_pages = sum(1 for p in processed_pages if p.llm_processed)
            total_chars = sum(len(p.text) for p in processed_pages)
            
            stats = {
                'total_pages': total_pages,
                'pages_processed': len(processed_pages),
                'llm_pages': llm_pages,
                'total_characters': total_chars,
                'avg_confidence': sum(p.confidence for p in processed_pages) / len(processed_pages) if processed_pages else 0,
                'output_dir': str(output_dir),
                'chapters_created': len(chapters)
            }
            
            logger.info(f"‚úÖ Processamento conclu√≠do: {stats}")
            
            return {
                'success': True,
                'processed_pages': processed_pages,
                'chapters': chapters,
                'stats': stats,
                'metadata': metadata
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erro processando livro: {e}")
            return {
                'success': False,
                'error': str(e),
                'processed_pages': [],
                'chapters': [],
                'stats': {}
            }
    
    def _organize_into_chapters(self, pages: List[PDFPage], 
                               metadata: BookMetadata, 
                               output_dir: Path) -> List[Dict[str, Any]]:
        """Organiza p√°ginas em cap√≠tulos."""
        chapters = []
        pages_per_chapter = 10  # 10 p√°ginas por cap√≠tulo
        
        for i in range(0, len(pages), pages_per_chapter):
            chapter_num = (i // pages_per_chapter) + 1
            chapter_pages = pages[i:i + pages_per_chapter]
            
            # Conte√∫do do cap√≠tulo
            chapter_text = ""
            for page in chapter_pages:
                chapter_text += f"\n\n--- P√°gina {page.page_num} ---\n\n{page.text}\n"
            
            # Nome do arquivo
            filename = f"capitulo-{chapter_num:03d}.md"
            filepath = output_dir / filename
            
            # Frontmatter
            frontmatter = f"""---
title: "Cap√≠tulo {chapter_num}: P√°ginas {chapter_pages[0].page_num}-{chapter_pages[-1].page_num}"
book: "{metadata.title}"
author: "{metadata.author}"
chapter: {chapter_num}
pages: "{chapter_pages[0].page_num}-{chapter_pages[-1].page_num}"
llm_pages: {sum(1 for p in chapter_pages if p.llm_processed)}
confidence: {sum(p.confidence for p in chapter_pages) / len(chapter_pages):.2f}
processed_date: "{datetime.now().isoformat()}"
---

"""
            
            # T√≠tulo e conte√∫do
            content = f"# Cap√≠tulo {chapter_num}\n\n"
            content += chapter_text
            
            # Se temos LLM, adiciona se√ß√£o de an√°lise
            if self.llm and chapter_num <= 3:  # Apenas para os primeiros 3 cap√≠tulos (para n√£o sobrecarregar)
                try:
                    analysis = self._analyze_chapter(chapter_text, metadata, chapter_num)
                    content += f"\n\n## üß† An√°lise Autom√°tica\n\n{analysis}\n"
                except Exception as e:
                    logger.warning(f"Erro analisando cap√≠tulo {chapter_num}: {e}")
                    content += f"\n\n## üß† An√°lise Autom√°tica\n\n*An√°lise n√£o dispon√≠vel devido a erro: {str(e)[:100]}*\n"
            
            # Se√ß√£o para notas do usu√°rio
            content += f"\n\n## üìù Notas\n\n<!-- Adicione suas anota√ß√µes aqui -->\n"
            
            # Salva arquivo completo
            full_content = frontmatter + content
            filepath.write_text(full_content, encoding='utf-8')
            
            chapters.append({
                'number': chapter_num,
                'filename': filename,
                'filepath': str(filepath),
                'pages': f"{chapter_pages[0].page_num}-{chapter_pages[-1].page_num}",
                'llm_pages': sum(1 for p in chapter_pages if p.llm_processed),
                'content_preview': chapter_text[:500] + "..." if len(chapter_text) > 500 else chapter_text
            })
            
            logger.debug(f"‚úÖ Cap√≠tulo {chapter_num} salvo: {filename}")
        
        return chapters
    
    def _analyze_chapter(self, content: str, metadata: BookMetadata, 
                        chapter_num: int) -> str:
        """Usa LLM para analisar o conte√∫do do cap√≠tulo."""
        if not self.llm:
            return "*LLM n√£o dispon√≠vel para an√°lise*"
        
        try:
            # Cria prompt para an√°lise
            prompt = f"""Analise este cap√≠tulo do livro "{metadata.title}" de {metadata.author}:

CAP√çTULO: {chapter_num}

CONTE√öDO (resumido):
{content[:1500]}...

Forne√ßa uma an√°lise filos√≥fica concisa:
1. Tema principal (1-2 frases)
2. 2-3 conceitos filos√≥ficos presentes
3. Como se relaciona com a obra como um todo
4. 1 quest√£o para reflex√£o

Seja direto e filos√≥fico, evite formalidades excessivas."""
            
            response = self.llm.generate(prompt, use_semantic=True)
            
            if response and "text" in response:
                return response["text"]
            else:
                return "*An√°lise n√£o dispon√≠vel*"
                
        except Exception as e:
            logger.warning(f"Erro analisando cap√≠tulo {chapter_num}: {e}")
            return f"*Erro na an√°lise: {str(e)[:50]}*"